# -*- coding: utf-8 -*-
"""8 Logestic regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ycWCLL-SfV8ZBu0U21KAg3dima9AB8Ng
"""

import pandas as pd
from matplotlib import pyplot as plt

!git clone 'https://github.com/sachinkavindaa/Machine-learning-with-Python'

df =pd.read_csv('/content/Machine-learning-with-Python/ML/8 Logestic regression/insurance_data.csv')
df

plt.scatter(df.age,df.bought_insurance,marker='*',color='red')

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test = train_test_split(df[['age']],df.bought_insurance,test_size = 0.1)

X_test

y_test

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()

model.fit(X_train,y_train)

model.predict(X_test)

model.score(X_test,y_test)

model.predict_proba(X_test)

model.coef_

model.intercept_

import math
def sigmoid(x):
  return 1/(1+math.exp(-x))

def prediction_func(age):
  z = 0.124*age - 4.94
  y = sigmoid(z)
  return y

age = 75
prediction_func(age)  #0.98 seems to reach 1. then buy insurance

age = 13
prediction_func(age)  #0,035 seems to reach 0. don not buy insurance

